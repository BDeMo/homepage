---
permalink: /
title: "Mingjia (Samuel Jayden) Shi: An dreamer learning and practicing constantly."
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

News
======
<font color="red">Actively applying for a 2025 Fall PhD!</font> If you are interested in a student familiar with theoretical analysis, generative model with extensive industry experiences as well, feel free to [Mail](3101ihs@gmail.com)!

Biography
======
In 2024, I completed my master degree at Sichuan University majored in Artificial Intelligence, right where I had completed my bachelor's degree before, supervised by Prof. [Jiancheng Lv](https://center.dicalab.cn/). The majors of my career in Sichuan University are optimization and distributed learning (e.g., decentralized optimization and federated learning), and it's the second year as an intern student of [NUS HPC-Lab](https://ai.comp.nus.edu.sg/), and I enojoy the challenges and interesting topics here (e.g. efficient AI, generative model, parameter generation and etc.). During the period of study, as an author and reviewer of Top AI Conferences and Journals, I have appreciated the fascination of research and what I want to do. I pursue further studies, a phd career, and more insights about the nature of AI and the world. I wanna the difficulties encountered not to be KPIs and dull, but rather my own incompetence.

Research Interests
======
The works in hands are about both theoretical analyses and corresponding methods about Generative Models, LLM Safety Alignment, and Federated Learning.


- **Distributed Learning and Optimization**:
Distributed learning is the last one I majored in. The works explore the heterogeneity composition in federated learning primarily from the perspective of information composition, with methods towards information theory and optimization (e.g., maximum expectation algorithms and Bayesian learning). Also involved in the distributed area are load balancing and communication compression. Participating roles include theory, methodology, engineering and promotion.


- **Efficient AI**:
Efficient AI is the recent major engagements and expected future major directions. To improve efficiency, especially training, in AI applications, the works in hands are mainly about data-centric AI and optimization.


- **Generative Model**:
Works about Generative Model interest me the most recently. The big hitter, generative model well-supported by diffusion theory, bring me back to the wonders of physics. A theoretically grounded approach is always fascinating. There are countless ideas whenever thermodynamics is mentioned, and in the diffusion model I vaguely see the unification of chemical entropy and information entropy on stochastic processes from the Bayesian view.


- **LLM Safety and Privacy**:
Another big hitter, LLM, and its practical generation tasks are also of my interests. Being the moon, this field in has a lot of special phenomena as well as things that need to be explained, all of which titillate the curiosity. Similarly, there are a lot of industrial things that need to be solved, for the sake of sixpence, such as, effiicency, human value alignment and privacy. The variety of empirical phenomena of deep learning at scale is equally fascinating.